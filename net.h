//// Created by Kliment Serafimov on 2019-02-16.//#ifndef NEURAL_GUIDED_DECISION_TREE_SYNTHESIS_NET_H#define NEURAL_GUIDED_DECISION_TREE_SYNTHESIS_NET_H#include "Header.h"#include "bit_signature.h"#include "util.h"#include "layered_graph.h"#include "batch.h"class net: public layered_graph{public:    typedef pair<int, vector<bit_signature> > deltaPredict;    typedef pair<pair<deltaPredict, deltaPredict>, vector<bit_signature> > deltaState;    map<pair<pair<int, int>, pair<int, int> >, int> state_action_change;    map<deltaState, int> delta_knowledge_graph;// [actor, actor_deltaPredict, state, state_deltaPredict, delta_actor_state]    map<pair<pair<int, vector<bit_signature> >, vector<bit_signature> >, int> new_neurons;    map<vector<bit_signature>, set<deltaState> > clasify_neurons;    map<vector<bit_signature>, int> count_neuron_activation;    vector<pair<vector<layer>, int> >  evolve;    int stress;    void init()    {        stress = 1;    }    net()    {        init();    }    net(net* other): layered_graph(*other)    {    }    net(layered_graph _net): layered_graph(_net)    {    }    bool invariant()    {        return numInputs>=1 && numOutputs>=1;    }    net(int in_bits, int *hiddenLayers, int out_bits)    {        init();        numInputs = in_bits;        numOutputs = out_bits;        assert(invariant());        constructNN(hiddenLayers);    }    net(int in_bits, int only_layer, int out_bits)    {        init();        numInputs = in_bits;        numOutputs = out_bits;        assert(invariant());        int hiddenLayers[3] = {only_layer, -1};        constructNN(hiddenLayers);    }    net(int in_bits, int only_layer, int out_bits, vector<bit_signature> all_w)    {        init();        numInputs = in_bits;        numOutputs = out_bits;        assert(invariant());        int hiddenLayers[3] = {only_layer, -1};        constructNN(hiddenLayers, all_w);    }    net(int in_bits, int first_layer, int second_layer, int out_bits)    {        init();        numInputs = in_bits;        numOutputs = out_bits;        assert(invariant());        int hiddenLayers[3] = {first_layer, second_layer, -1};        constructNN(hiddenLayers);    }    net(int in_bits, int out_bits)    {        init();        numInputs = in_bits;        numOutputs = out_bits;        assert(invariant());        int hiddenLayers[2] = {numInputs, -1};        constructNN(hiddenLayers);    }    net(int in_bits, vector<int> hidden_block, int out_bits)    {        init();        numInputs = in_bits;        numOutputs = out_bits;        assert(invariant());        int hiddenLayers[hidden_block.size()+1];        for(int i = 0;i<hidden_block.size();i++)        {            hiddenLayers[i] = hidden_block[i];        }        hiddenLayers[hidden_block.size()] = -1;        constructNN(hiddenLayers);    }    /*net(int in_bits, vector<int> special, int out_bits)    {        init();        numInputs = in_bits;        numOutputs = out_bits;        assert(invariant());        single_construct_neuron(special);    }*/    vector<bit_signature> to_bit_signature_vector()    {        vector<bit_signature> ret;        for(int i = 0;i<layers.size();i++)        {            for(int j = 0;j<layers[i].neurons.size(); j++)            {                for(int k = 0; k<layers[i].neurons[j].w.size(); k++)                {                    ret.push_back(layers[i].neurons[j].get_weight(k));                    ret.back().vector_id = (int)ret.size()-1;                }                ret.push_back(layers[i].neurons[j].t);                ret.back().vector_id = (int)ret.size()-1;            }        }        return ret;    }    void set_special_weights()    {        double best_NN[2][3][2][3] =        {            {                { {-0.779866, 1.121839, 1.055121}, {2.088129} },                { {1.056540, -0.133746, 3.917589}, {-3.799220} },                { {3.199659, -1.668193, 1.093140}, {0.776509} }            },            {                { {8.831709, -9.379355, 5.482632}, {-1.813432} }            }        };        /*double best_NN[2][6][2][6] =        {            {                { {-4.309201, 5.138296, -1.152481}, {2.320547} },                { {-0.649062, -2.472168, -2.804680}, {0.168673} },                { {0.701712, 2.243995, -2.418635}, {-0.759451} },                { {0.235270, 1.145910, 3.324338}, {-0.780821} },                { {0.997694, 2.663606, 0.698597}, {-2.832949} },                { {-1.814058, -1.621025, 2.618545}, {2.610781} }            },            {                { {1.197346, 8.692561, -5.611454, 5.719130, 4.052991, -7.907357}, {6.185411} }            }        };*/        /*double best_NN[2][6][6]        {            {                {13.75, 2.97, -7.82},                {-3.32, 4.14, -3.26},                {-6.08, -9.76, 4.84},                {2.18, 5.75, 4.25},                {1.82, -12.43, -1.41},                {2.55, -2.13, 2.74}            },            {                {-3.88, -11.21, -3.09, 10.97, 4.96, -11.10}            }        };        double offsets[2][6] =        {            {                -1.78, -2.63, -0.33, 2.89, 2.79, -2.75            },            {                -11.91            }        };*/        assert(layers.size() == 2);        for(int i = 0;i<layers.size();i++)        {            //if(i == 1)assert(layers[i].neurons.size() == 1);            //if(i == 0)assert(layers[i].neurons.size() == 6);            for(int j = 0;j<layers[i].neurons.size();j++)            {                //if(i == 1)assert(layers[i].neurons[j].w.size() == 6);                //if(i == 0)assert(layers[i].neurons[j].w.size() == 3);                for(int k = 0; k<layers[i].neurons[j].w.size(); k++)                {                    layers[i].neurons[j].w[k] = best_NN[i][j][0][k];                }                layers[i].neurons[j].t = best_NN[i][j][1][0];            }        }    }    layered_graph last_save;    void save_weights()    {        last_save = layered_graph(*this);    }    void compare_to_save()    {        assert(layers.size() == last_save.layers.size());        cout << "W = " <<endl;        cout << "{" <<endl;;        for(int i = 0;i<layers.size();i++)        {            if(i!=0)            {                cout  << ", " <<endl;            }            assert(layers[i].neurons.size() == last_save.layers[i].neurons.size());            cout << indent(1) << "{" <<endl;            for(int j = 0;j<layers[i].neurons.size();j++)            {                assert(layers[i].neurons[j].w.size() == last_save.layers[i].neurons[j].w.size());                if(j != 0)                {                    cout << ", " <<endl;;                }                cout << indent(2)<< "{";                for(int k = 0; k<layers[i].neurons[j].w.size(); k++)                {                    if(k != 0)                    {                        cout << ", ";                    }                    cout << layers[i].neurons[j].w[k] - last_save.layers[i].neurons[j].w[k];                }                cout << "}";            }            cout << endl << indent(1) << "}";        }        cout << endl << "}" << endl;        cout << "BIAS = " <<endl;;        cout << "{" << endl;        for(int i = 0;i<layers.size();i++)        {            if(i!=0)            {                cout << ", " <<endl;            }            cout << indent(1) << "{" <<endl;            assert(layers[i].neurons.size() == last_save.layers[i].neurons.size());            for(int j = 0;j<layers[i].neurons.size();j++)            {                if(j!= 0)                {                    cout <<", "<< endl;                }                cout << indent(2) << layers[i].neurons[j].t - last_save.layers[i].neurons[j].t;            }            cout << endl << indent(1) << "}";        }        cout << endl << "}" << endl;    }    batch_element get_batch_element(net* network, Data* latice, int _id)    {        batch_element ret(_id);        ret.network_output = network->forwardPropagate(latice->in[ret.id], false);        ret.error_vector = get_error_vector(latice->out[ret.id], ret.network_output, 2);        ret.representative_error = ret.error = max_of_vector(ret.error_vector);        return ret;    }    /*batch_element get_batch_element(net* network, Data* latice, int _id, vector<bit_signature> mask)    {        batch_element ret(_id);        ret.network_output = network->forwardPropagate(latice->in[ret.id], false);        ret.error_vector = get_error_vector(latice->out[ret.id], ret.network_output, 2);        ret.error = sum_vector(ret.error_vector);        vector<bit_signature> masked_error_vector = pairwise_product(ret.error_vector, mask);        ret.representative_error = -sum_vector(masked_error_vector);        return ret;    }*/    /*void train(Data *latice, double rate, int parameter, string type)     {     if(type == "harder priority train")     {     harderPriorityTrain(latice, rate, parameter);     }     else     {     assert(0);     }     }*/    void set_random_w()    {        for(int i = 0;i<layers.size();i++)        {            layers[i].set_random_w();        }    }    void minus(net other)    {        assert(layers.size() == other.layers.size());        for(int i = 0;i<layers.size();i++)        {            layers[i].minus(other.layers[i]);        }    }    void mul(double alpha)    {        for(int i = 0;i<layers.size();i++)        {            layers[i].mul(alpha);        }    }    class parameters    {        bool single_rate = true;        double rate = 1;        bool iteration_count_set = false;        int iteration_count = 0;        bool fraction_of_samples_set = false;        double fraction_of_samples = 0;        bool number_resets_defined = false;        int number_resets;        bool meta_iteration_count_set = false;        int meta_iteration_count;        bool leaf_iters_set = false;        vector<int> leaf_iters;    public:        vector<net*> progressive_nets;        vector<vector<net*> > ensamble_progressive_nets;        DecisionTreeSynthesiserType decision_tree_synthesiser_type;        int (net::*priority_train_f)(Data*, parameters);        int first_layer = -1;        net* neural_net = NULL;        int num_stale_iterations_defined = false;        int num_stale_iterations = -1;        int batch_width = 1;        double min_rate = 1;        double max_rate = 1;        int ensamble_size = 1;        double accuracy = 0.5;        bool track_dimension_model = true;        parameters()        {        }        parameters(double _rate)        {            rate = _rate;            min_rate = rate;            max_rate = rate;        }        void set_leaf_iters(vector<int> _leaf_iters)        {            leaf_iters_set = true;            leaf_iters = _leaf_iters;        }        parameters(vector<int> _leaf_iters)        {            set_leaf_iters(_leaf_iters);        }        parameters(double _rate, int _batch_width)        {            rate = _rate;            min_rate = rate;            max_rate = rate;            batch_width = _batch_width;        }        parameters(double _rate, int _batch_width,  int _iteration_count)        {            rate = _rate;            min_rate = rate;            max_rate = rate;            batch_width = _batch_width;            iteration_count_set = true;            iteration_count = _iteration_count;        }        parameters(double _rate, int _batch_width,  double _fraction_of_samples)        {            rate = _rate;            min_rate = rate;            max_rate = rate;            batch_width = _batch_width;            fraction_of_samples_set = true;            fraction_of_samples = _fraction_of_samples;        }        int get_first_layer(int defaul)        {            if(first_layer == -1) return defaul;            return first_layer;        }        void set_number_stale_itterations(int n)        {            num_stale_iterations = n;            num_stale_iterations_defined = true;        }        void set_number_resets(int _n)        {            number_resets = _n;            number_resets_defined = true;        }        int get_number_resets()        {            if(number_resets_defined) return number_resets;            else return 1;        }        void set_meta_iteration_count(int c)        {            meta_iteration_count_set = true;            meta_iteration_count = c;        }                int get_meta_iteration_count()        {            assert(meta_iteration_count_set);            return meta_iteration_count;        }        void set_iteration_count(int c)        {            iteration_count_set = true;            iteration_count = c;            if(fraction_of_samples_set)            {                iteration_count*=fraction_of_samples;                iteration_count = max(iteration_count, 1);            }        }        int get_iteration_count(int progressive_net_id)        {            assert(leaf_iters_set);            return leaf_iters[progressive_net_id];        }        int get_iteration_count()        {            assert(iteration_count_set);            return iteration_count;        }        double get_rate()        {            assert(single_rate);            return rate;        }        bool do_next_iteration(int num_iterations_so_far)        {            if(iteration_count_set)            {                return num_iterations_so_far < iteration_count;            }            else            {                return true;            }        }    };    int train(Data *latice, parameters parameter, int (net::*train_f)(Data*, parameters))    {        count_backprop = 0;        count_feedforward = 0;        int ret = (this->*train_f)(latice, parameter);        if(printCycle)        {            cout << "backprop: " << count_backprop <<endl;            cout << "feedforward: "<< count_feedforward << endl;        }        return ret;    }    /*     int train(Data *latice, double rate, parameters parameter, int (net::*train_f)(Data*, double, int))     {     count_backprop = 0;     count_feedforward = 0;     int ret = (this->*train_f)(latice, rate, parameter);     if(printCycle)     {     cout << "backprop: " << count_backprop <<endl;     cout << "feedforward: "<< count_feedforward << endl;     }     return ret;     }     int train(Data *latice, double rate, int (net::*train_f)(Data*, double))     {     count_backprop = 0;     count_feedforward = 0;     int ret = (this->*train_f)(latice, rate);     if(printCycle)     {     cout << "backprop: " << count_backprop <<endl;     cout << "feedforward: "<< count_feedforward << endl;     }     return ret;     }*/    map<pair<int, int>, int> learned_implication;    vector<int> dimension_difficulty_score;    vector<int> dimension_easy_score;    vector<bit_signature> dimension_cumulative_score;    void track_feature_of_dimensions(vector<int> &feature_score, vector<bit_signature> const &bitmask)    {        if(feature_score.size() == 0)        {            feature_score = vector<int>(bitmask.size(), 0);        }        assert(feature_score.size() == bitmask.size());        for(int i = 0;i<bitmask.size();i++)        {            if(bitmask[i]!=0)            {                assert((int)pow((int)sqrt(feature_score[i]), 2) == feature_score[i]);                feature_score[i] += 2*sqrt(feature_score[i])+1;            }        }    }    void print_max_feature_of_dimension(vector<int> const &feature, string const feature_name)    {        pair<int, int> ret = mp(-1, -1);        for(int i = 0;i<feature.size();i++)        {            ret = max(ret, mp(feature[i], i));        }        cout << "max " << feature_name <<" = " << ret.s <<endl;    }    bool max_error_element_q_init = false;    priority_queue<batch_element> max_error_element_q;    int iter = 1;    batch get_batch_of_maximal_error_examples(Data* latice, parameters param)//, vector<bit_signature> summary_error_mask)    {        assert(param.batch_width >= 1);        set<batch_element> ret_set;        /*if(!max_error_element_q_init)        {            for(int i = 0;i<latice->size();i++)            {                batch_element new_element = get_batch_element(this, latice, i);                new_element.iter = iter;                max_error_element_q.push(new_element);            }            max_error_element_q_init = true;        }        while(ret_set.size() < param.batch_width && !max_error_element_q.empty())        {            batch_element old_element = max_error_element_q.top();            max_error_element_q.pop();            if(old_element.iter == iter)            {                ret_set.insert(old_element);                old_element.iter = iter;            }            else            {                old_element = get_batch_element(this, latice, old_element.id);                old_element.iter = iter;                max_error_element_q.push(old_element);            }        }        iter++;        */        for(int i = 0;i<latice->size();i++)        {            batch_element new_element = get_batch_element(this, latice, i);//, summary_error_mask);            ret_set.insert(new_element);            if(ret_set.size() > param.batch_width)            {                ret_set.erase(ret_set.begin());            }            //cout << new_element.id <<" "<< new_element.error <<endl;        }        batch ret;        for(set<batch_element>::iterator it = ret_set.begin(); it!= ret_set.end(); it++)        {            max_error_element_q.push((*it));            ret.push_back((*it));        }        rev_v(ret.elements);        return ret;    }    batch get_set_of_examples_that_minimizes_error_of_set_of_maximum_error_examples(Data* latice, parameters param)    {        assert(param.batch_width >= 1);        batch examples_with_maxium_error = get_batch_of_maximal_error_examples(latice, param);        batch ret;        for(int j = 0;j<examples_with_maxium_error.elements.size();j++)        {            int id = examples_with_maxium_error.elements[j].id;            batch_element local_ret(5.0, -1);            for(int i = 0;i<latice->size();i++)            {                net local_net = net(copy());                batch_element try_element = get_batch_element(&local_net, latice, i);                local_ret = min(local_ret, try_element);                assert(local_ret.id != -1);            }            ret.push_back(local_ret);        }        return ret;    }    batch get_maximal_error_example(Data* latice, double rate, int num_examples)    {        assert(num_examples == 1);        batch_element local_ret(0.0, -1);        for(int i=0; i<latice->size(); i++)        {            batch_element try_element = get_batch_element(this, latice, i);            local_ret = max(local_ret, try_element);        }        batch ret;        ret.push_back(local_ret);        return ret;    }    batch get_examples_that_minimize_errors_of_given_examples(Data* latice, double rate, batch the_batch)    {        batch ret;        for(int j = 0;j<the_batch.elements.size();j++)        {            int id = the_batch.elements[j].id;            pair<double, int> local_ret = mp(500, -1);            for(int i = 0;i<latice->size();i++)            {                net local_net = net(copy());                local_net.backwardPropagate(latice->out[i], local_net.forwardPropagate(latice->in[i], true), rate, true);                batch_element test_element = get_batch_element(&local_net, latice, id);                local_ret = max(local_ret, mp(test_element.error, i));            }            ret.push_back(batch_element(local_ret.s));        }        return ret;    }    /*batch get_example_that_minimizes_error_of_maximum_error_example(Data* latice, double rate, int num_examples)     {     assert(num_examples == 1);     return get_examples_that_minimize_errors_of_given_examples(latice, rate, get_maximal_error_example(latice, rate, num_examples));     }*/    int harderPriorityTrain(Data *latice, parameters param)    {        return PriorityTrain(latice, param, &net::get_set_of_examples_that_minimizes_error_of_set_of_maximum_error_examples);    }    /*int hardPriorityTrain(Data *latice, parameters param)     {     return PriorityTrain(latice, param, &net::get_example_that_minimizes_error_of_maximum_error_example);     }*/    int softPriorityTrain(Data *latice, parameters param)    {        return PriorityTrain(latice, param, &net::get_batch_of_maximal_error_examples);    }    int stocasticPriorityTrain(Data *latice, parameters param)    {        return PriorityTrain(latice, param, &net::stocastic_priority);    }    int aveagePriorityTrain(Data *latice, parameters param)    {        return PriorityTrain(latice, param, &net::average_priority);    }    /*int brutalPriorityTrain(Data *latice, parameters param)    {        return PriorityTrain(latice, param, &net::get_batch_of_maximally_difficult_examples);    }*/    int count_unknown_examples(Data *latice, double accuracy)    {        int wrong = 0;        for(int i=0;i<latice->size();i++)        {            wrong+=!check(latice->out[i], forwardPropagate(latice->in[i], false), accuracy);        }        return wrong;    }    bool training_completed(Data* latice, double accuracy)    {        bool ret = true;        for(int i=0;i<latice->size();i++)        {            bool local = true;            if(!check(latice->out[i], forwardPropagate(latice->in[i], false), accuracy))            {                local = false;                ret = false;            }            //cout << local;        }        //cout << endl;        return ret;    }    //vector<bit_signature> summary_vector;    class data_model    {    public:        struct confusion_calc        {            bit_signature ratio_sum;            bit_signature input_delta_sum;            bit_signature score;            confusion_calc(bit_signature a, bit_signature b, bit_signature c)            {                ratio_sum = a;                input_delta_sum = b;                score = c;            }            int vector_id = -1;            bool operator < (const confusion_calc &other) const            {                if(score == 0 && other.score == 0)                {                    return ratio_sum < other.ratio_sum;                }                return score < other.score;            }        };        vector<confusion_calc> dimension_confusion;        vector<confusion_calc> dimension_confusion_by_category[2];        double trainee_confusion_sum_by_category[2] = {0, 0};        vector<confusion_calc> trainee_confusion_by_category[2];        double trainee_confusion_sum = 0;        vector<confusion_calc> trainee_confusion;        vector<vector<confusion_calc> > confusion;        vector<bit_signature> dimension_pair_der_ratio_score;        vector<bit_signature> dimension_pair_der_ratio_sum;        //vector<vector<bit_signature> > dimension_pair_input_delta_sum;        vector<vector<bit_signature> > dimension_pair_error_ratio_score;        vector<vector<bit_signature> > dimension_pair_error_ratio_sum;        vector<vector<bit_signature> > dimension_pair_input_delta_sum;        vector<vector<bit_signature> > dimension_bit_pair_error_ratio_score[2][2];        vector<vector<bit_signature> > dimension_bit_pair_error_ratio_sum[2][2];        vector<vector<bit_signature> > dimension_bit_pair_input_delta_sum[2][2];        vector<vector<bit_signature> > inout_dimension_error_ratio_score;        vector<vector<bit_signature> > inout_dimension_error_ratio_sum;        vector<vector<bit_signature> > inout_dimension_input_delta_sum;        vector<bit_signature> dimension_error_ratio_score;        vector<bit_signature> dimension_error_ratio_sum;        vector<bit_signature> dimension_input_delta_sum;        /*        vector<bit_signature> negative_delta_ins_sum;        vector<bit_signature> positive_delta_ins_sum;        vector<bit_signature> bit_weighted_negative_dimension;//[2];        vector<bit_signature> negative_dimensions;        vector<bit_signature> positive_dimensions;        vector<vector<bit_signature> > dont_care_delta_ins_sum;        vector<vector<bit_signature> > dont_care_dimension_per_example;        vector<vector<bit_signature> > care_delta_ins_sum;        vector<vector<bit_signature> > care_dimension_per_example;        vector<vector<bit_signature> > max_delta;        vector<vector<vector<bit_signature> > > non_dominating;        */        vector<batch_element> prev_error_of_samples;        vector<bit_signature> summary_error_mask;        vector<vector<bit_signature> > error_mask_per_dimension;        data_model(){}        batch_element get_batch_element(net* network, Data* latice, int _id)        {            batch_element ret(_id);            ret.network_output = network->forwardPropagate(latice->in[ret.id], false);            ret.error_vector = get_error_vector(latice->out[ret.id], ret.network_output, 2);            ret.representative_error = ret.error = sum_vector(ret.error_vector);            return ret;        }        data_model(net* home, Data* latice)        {            for(int i = 0;i<latice->size();i++)            {                net tmp;                prev_error_of_samples.push_back(get_batch_element(home, latice, i));            }            clear_and_init(latice);        }        void clear_and_init(Data* latice)        {            dimension_confusion_by_category[0] = dimension_confusion_by_category[1] = vector<confusion_calc>(latice->numInputs, {0, 0, 0});            dimension_confusion = vector<confusion_calc>(latice->numInputs, {0, 0, 0});            trainee_confusion_sum_by_category[0] = trainee_confusion_sum_by_category[1] = 0;            trainee_confusion_by_category[0] = trainee_confusion_by_category[1] = vector<confusion_calc>((int)latice->size(), {0, 0, 0});            trainee_confusion_sum = 0;            trainee_confusion = vector<confusion_calc>((int)latice->size(), {0, 0, 0});            confusion = vector<vector<confusion_calc> >(latice->size(), vector<confusion_calc>(latice->size(), {0.0, 0.0, 0.0}));            int n = latice->numInputs, m = latice->numOutputs;            inout_dimension_error_ratio_score = vector<vector<bit_signature> >(m, vector<bit_signature>(n, 0));            inout_dimension_error_ratio_sum = vector<vector<bit_signature> >(m, vector<bit_signature>(n, 0));            inout_dimension_input_delta_sum = vector<vector<bit_signature> >(m, vector<bit_signature>(n, 0));            dimension_pair_error_ratio_score = vector<vector<bit_signature> >(n, vector<bit_signature>(n, 0));            dimension_pair_error_ratio_sum = vector<vector<bit_signature> >(n, vector<bit_signature>(n, 0));            dimension_pair_input_delta_sum = vector<vector<bit_signature> >(n, vector<bit_signature>(n, 0));            for(int i = 0;i<2;i++)            {                for(int j = 0;j<2;j++)                {                    dimension_bit_pair_error_ratio_score[i][j] = vector<vector<bit_signature> >(n, vector<bit_signature>(n, 0));                    dimension_bit_pair_error_ratio_sum[i][j] = vector<vector<bit_signature> >(n, vector<bit_signature>(n, 0));                    dimension_bit_pair_input_delta_sum[i][j] = vector<vector<bit_signature> >(n, vector<bit_signature>(n, 0));                }            }            dimension_pair_der_ratio_score.clear();            dimension_pair_der_ratio_score.resize(latice->numInputs, 0);            dimension_pair_der_ratio_sum.clear();            dimension_pair_der_ratio_sum.resize(latice->numInputs, 0);            dimension_error_ratio_score.clear();            dimension_error_ratio_score.resize(latice->numInputs, 0);            dimension_error_ratio_sum.clear();            dimension_error_ratio_sum.resize(latice->numInputs, 0);            dimension_input_delta_sum.clear();            dimension_input_delta_sum.resize(latice->numInputs, 0);        }        batch calculate_confusion(Data* latice, parameters param, net* home)        {            confusion = vector<vector<confusion_calc> >(latice->size(), vector<confusion_calc>(latice->size(), {0.0, 0.0, 0.0}));            vector<bit_signature> prev_errors;            for(int j = 0;j<latice->size();j++)            {                batch_element elem = get_batch_element(home, latice, j);                prev_errors.push_back(elem.error);            }            //trainee_confusion = vector<confusion_calc>((int)latice->size(), {0, 0, 0});            vector<confusion_calc> trainer_confusion((int)latice->size(), {0, 0, 0});            //vector<confusion_calc> score_sum((int)latice->size(), {0, 0, 0});            double total_local_ratio_sum = 0;            for(int i = 0;i<latice->size(); i++)            {                batch_element trainer_prev = get_batch_element(home, latice, i);                net tmp_net = *home;                tmp_net.backwardPropagate(latice->out[i], tmp_net.forwardPropagate(latice->in[i], true), param.get_rate(), true);                batch_element trainer_new = get_batch_element(&tmp_net, latice, i);                double trainer_ratio = trainer_new.error/trainer_prev.error;                trainer_confusion[i].vector_id = i;                for(int j = 0; j<latice->size();j++)                {                    trainee_confusion[j].vector_id = j;                    trainee_confusion_by_category[(latice->out[j][0] == 1)][j].vector_id = j;                    trainee_confusion_by_category[(latice->out[j][0] == 0)][j].vector_id = j;                    /*if(!(latice->out[i][0] == 1))// && latice->out[j][0] == 1))                    {                        continue;                    }*/                    batch_element elem = get_batch_element(&tmp_net, latice, j);                    double ratio = (elem.error/prev_errors[j]);                    double sum_input_delta = 0;                    for(int k = 0;k<latice->numInputs;k++)                    {                        sum_input_delta+=abs(latice->in[j][k] - latice->in[i][k]);                    }                    if(sum_input_delta != 0)                    for(int k = 0;k<latice->numInputs;k++)                    {                        double input_delta = abs(latice->in[j][k] - latice->in[i][k])/sum_input_delta;                        double weighed_ratio = ratio*input_delta;                        dimension_confusion[k].ratio_sum+=weighed_ratio;                        dimension_confusion[k].input_delta_sum+=input_delta;                        dimension_confusion_by_category[(latice->out[j][0] == 1)][k].ratio_sum+=weighed_ratio;                        dimension_confusion_by_category[(latice->out[j][0] == 1)][k].input_delta_sum+=input_delta;                    }                    //ratio = ratio/trainer_ratio;                    trainee_confusion_by_category[(latice->out[j][0] == 1)][j].input_delta_sum+=1;                    trainee_confusion_by_category[(latice->out[j][0] == 1)][j].ratio_sum+=ratio;                    trainee_confusion_sum_by_category[(latice->out[j][0] == 1)]+=ratio;                    confusion[i][j].score = ratio;                    trainee_confusion[j].input_delta_sum += 1;                    trainee_confusion[j].ratio_sum += ratio;                    trainer_confusion[i].score += ratio;                    trainee_confusion_sum+=ratio;                    total_local_ratio_sum+=ratio;                    //cout << i <<" "<<j <<" "<< ratio <<endl;                }            }            /*double local_check = 0;            for(int i = 0;i<latice->size();i++)            {                trainee_confusion[i].vector_id = i;                trainee_confusion[i].score/=total_local_ratio_sum;                local_check += trainee_confusion[i].score;            }            for(int i = 0;i<dimension_confusion.size();i++)            {                dimension_confusion[i].vector_id = i;                if(dimension_confusion[i].input_delta_sum != 0)                    dimension_confusion[i].score = dimension_confusion[i].ratio_sum/dimension_confusion[i].input_delta_sum;                else                {                    dimension_confusion[i].score = 0;                }                dimension_error_ratio_score[i] = dimension_confusion[i].score;            }*/            /*sort_v(dimension_confusion);            cout << "dimension confusion" <<endl;            for(int i = 0;i<dimension_confusion.size();i++)            {                cout << dimension_confusion[i].vector_id <<" "<< dimension_confusion[i].score <<endl;            }            cout << endl;*/            /*            vector<confusion_calc> weighted_batch((int)latice->size(), {0, 0, 0});            double second_check = 0;            for(int i = 0;i<latice->size();i++) // the trainer            {                weighted_batch[i].vector_id = i;                for(int j = 0;j<latice->size();j++) // the trainee                {                    weighted_batch[i].score+=(confusion[i][j].score*trainee_confusion[j].score);//trainer_confusion[i].score;                }                second_check+=weighted_batch[i].score;            }            sort_v(weighted_batch);            //rev_v(weighted_batch);            sort_v(trainee_confusion);            rev_v(trainee_confusion);            */            batch ret;            /*for(int i = 0;i<min(param.batch_width, (int)weighted_batch.size());i++)            {                ret.push_back(batch_element(weighted_batch[i].vector_id));            }*/            int print_c = 16;            /*cout << "votes for trainers sum = " << second_check << endl;            for(int i = 0;i<min(print_c, (int)weighted_batch.size());i++)            {                cout << "(" << fixed << setprecision(6) << latice->printInput(weighted_batch[i].vector_id) <<", "<< weighted_batch[i].score <<"); " << endl;;            }*/            /*cout << "confusion per example sum = " << local_check << endl;            for(int i = 0;i<min(print_c, (int)trainee_confusion.size());i++)            {                cout << "(" << fixed << setprecision(6) << latice->printInput(trainee_confusion[i].vector_id) <<", "<< trainee_confusion[i].score <<"); " << endl;;            }            cout << endl;*/            return ret;            /*cout << endl;            cout << "least = ";            for(int i = score_sum.size()-1;i>=score_sum.size()-5;i--)            {                cout << "(" << latice->printInput(score_sum[i].vector_id) <<", "<< score_sum[i].score <<"); ";            }            cout << endl;*/        }        /*batch solve_confusion(Data* latice, parameters param, net* home)        {            //update_dimension_summary(home, latice, the_batch, trainer_error_ratio_vector, trainer_error_ratio, true);        }*/        void update_dimension_summary(net* home, Data* latice, batch the_batch, vector<bit_signature> trainer_error_ratio_vector, double trainer_error_ratio)        {            update_dimension_summary(home, latice, the_batch, trainer_error_ratio_vector, trainer_error_ratio, false);        }        bool double_dimension = false;        bool inout_dimension = false;        void update_dimension_summary(net* home, Data* latice, batch the_batch, vector<bit_signature> trainer_error_ratio_vector, double trainer_error_ratio, bool single_iter)        {            if(single_iter)clear_and_init(latice);            //update_summary_error_mask(home, latice, the_batch);            //assert(negative_dimensions.size() == latice->numInputs);            //assert(positive_dimensions.size() == latice->numInputs);            the_batch.set_inputs(latice);            for(int i = 0;i<latice->size();i++)            {                batch_element updated_element = get_batch_element(home, latice, i);//sum_vector(get_error_vector(latice->out[i], forwardPropagate(latice->in[i], false)));                double trainee_error = (updated_element.error/prev_error_of_samples[i].error);                vector<double> delta_inputs;                double sum_input_delta = 0;                double sum_pair_input_delta = 0;                for(int dimension_id = 0; dimension_id<latice->numInputs;dimension_id++)                {                    double delta_input = abs(the_batch.input_average[dimension_id] - latice->in[i][dimension_id]);                    delta_inputs.push_back(delta_input);                    sum_input_delta += delta_input;                    for(int second_id = dimension_id+1; second_id<latice->numInputs;second_id++)                    {                        sum_pair_input_delta += abs(the_batch.input_average[dimension_id] - latice->in[i][dimension_id])*abs(the_batch.input_average[second_id] - latice->in[i][second_id]);                    }                }                /*trainee_confusion[i].vector_id = i;                trainee_confusion[i].ratio_sum += trainee_error;                trainee_confusion_sum += trainee_error;*/                if(sum_input_delta != 0)                    for(int dimension_id = 0;dimension_id<latice->numInputs;dimension_id++)                    {                        //imash cuvstvo deka ova ke raboti. keep your feelings accountable                        double input_delta_ratio = delta_inputs[dimension_id]/sum_input_delta;                        double error_ratio = trainee_error;//trainer_error_ratio;                        double ratio = input_delta_ratio*error_ratio;                        dimension_error_ratio_sum[dimension_id] += ratio;                        dimension_input_delta_sum[dimension_id] += input_delta_ratio;                        int f_d_id = dimension_id;                        if(double_dimension)                        for(int s_d_id = f_d_id+1; s_d_id < latice->numInputs; s_d_id++)                        {                            double input_pair_delta_ratio = delta_inputs[f_d_id]*delta_inputs[s_d_id]/sum_pair_input_delta;                            double pair_error_ratio = trainee_error/trainer_error_ratio;                            double pair_ratio = input_pair_delta_ratio*pair_error_ratio;                            dimension_pair_error_ratio_sum[f_d_id][s_d_id] += pair_ratio;                            dimension_pair_input_delta_sum[f_d_id][s_d_id] += input_pair_delta_ratio;                            int f_id = (latice->in[i][f_d_id] == 1);                            int s_id = (latice->in[i][s_d_id] == 1);                            dimension_bit_pair_error_ratio_sum[f_id][s_id][f_d_id][s_d_id] += pair_ratio;                            dimension_bit_pair_input_delta_sum[f_id][s_id][f_d_id][s_d_id] += input_pair_delta_ratio;                            /* to explore                             for(int func_id = 0; func_id < (1<<4); func_id++)                             {                             int func_in = ((f_id<<0)|(s_id<<1));                             int func_out = func_id&func_in;                             dimension_input_bit_pair_hash_value[f_d_id][s_d_id][f_id][s_id][func_out] = ;                             dimension_input_bit_pair_hash_function[f_d_id][s_d_id][func_id][f_id][s_id]/ *[func_out]* / = ;                             }*/                        }                        if(inout_dimension)                        for(int out_id = 0; out_id<latice->numOutputs; out_id++)                        {                            //double input_delta_ratio = delta_inputs[dimension_id]/sum_input_delta;                            double local_trainee_error = (updated_element.error_vector[out_id]/prev_error_of_samples[i].error_vector[out_id]);                            double local_trainer_error = trainer_error_ratio_vector[out_id];                            double local_error_ratio = local_trainee_error/local_trainer_error;                            double local_ratio = input_delta_ratio*local_error_ratio;                            inout_dimension_error_ratio_sum[out_id][dimension_id]+=local_ratio;                            inout_dimension_input_delta_sum[out_id][dimension_id]+=input_delta_ratio;                        }                    }                prev_error_of_samples[i] = updated_element;            }            if(single_iter)close(latice);            /*vector<bit_signature> ordered_dimensions = sort_single_dimensions();             for(int i = 0;i<ordered_dimensions.size();i++)             {             if(ordered_dimensions[i].vector_id ==0 || ordered_dimensions[i].vector_id == 7)             //ordered_dimensions[i].vector_id == ordered_dimensions.size()/2)             cout << ordered_dimensions[i].vector_id <<" ";             else cout << ". ";             }             for(int i = 0;i<the_batch.elements.size();i++)             {             cout << the_batch.elements[i].id<<" ";             }             cout << endl;*/        }        void close(Data* latice)        {            if(print_close_local_data_model)            {                cout << endl << "init" <<endl;                //cout << "total trainee_confusion" <<endl;                sort_v(trainee_confusion);                for(int i = 0;i<trainee_confusion.size();i++)                {                    int id = trainee_confusion[i].vector_id;                    trainee_confusion[i].score =  trainee_confusion[i].ratio_sum/trainee_confusion[i].input_delta_sum;                    //cout << latice->printInput(id)<<"\t"<<latice->printOutput(id) <<"\t" <<trainee_confusion[i].score <<endl;                }                //cout << endl;                /*                for(int category = 0;category<2;category++)                {                    cout << "trainee_confusion category " << category <<endl;                    sort_v(trainee_confusion_by_category[category]);                    for(int i = 0;i<trainee_confusion_by_category[category].size();i++)                    {                        int id = trainee_confusion_by_category[category][i].vector_id;                        trainee_confusion_by_category[category][i].score =  trainee_confusion_by_category[category][i].ratio_sum/trainee_confusion_by_category[category][i].input_delta_sum;                        cout << latice->printInput(id)<<"\t"<<latice->printOutput(id) <<"\t" <<trainee_confusion_by_category[category][i].score <<endl;                    }                    cout << endl;                }*/                for (int dim_id = 0; dim_id<latice->numInputs; dim_id++)                {                 /*   double sum[2][2] = {0, 0};                    for(int i = 0;i<trainee_confusion.size();i++)                    {                        int id = trainee_confusion[i].vector_id;                        sum[(latice->in[id][dim_id] == 1)]+=trainee_confusion[i].score;                    }                    //needs to be a weighted sum over  categories.                    cout << "new metric: " << dim_id <<" :: "<< max(sum[0], sum[1])/min(sum[0], sum[1]) << endl;                    */                    int per_branch[2] = {0, 0};                    int count[2][2] = {{0, 0}, {0, 0}};                    double boundaries[2][2][2] = {{{100, 0}, {100, 0}}, {{100, 0}, {100, 0}}};                    for(int i = 0;i<trainee_confusion.size();i++)                    {                        int id = trainee_confusion[i].vector_id;                        int branch = (latice->in[id][dim_id] == 1);                        per_branch[branch]++;                        int label = (latice->out[id][dim_id] == 1);                        count[label][branch]++;                        boundaries[label][branch][0]=min(boundaries[label][branch][0], trainee_confusion[i].score.value);                        boundaries[label][branch][1]=max(boundaries[label][branch][1], trainee_confusion[i].score.value);                        cout << boundaries[label][branch][0]  << " "<< trainee_confusion[i].score.value << endl;                    }                    for(int b_3 = 0; b_3<(1<<3);b_3++)                    {                        int i = ((b_3&(1<<0)) != 0);                        int j = ((b_3&(1<<1)) != 0);                        int k = ((b_3&(1<<2)) != 0);                        //cout << i << j << k << " "<< boundaries[i][j][k] <<endl;                    }                    int total = per_branch[0]+per_branch[1];                    assert(total == trainee_confusion.size());                    double score_per_branch[2] = {0, 0};                    double score = 0;                    for(int b_2 = 0;b_2<2;b_2++)                    {                        //int i = ((b_2&(1<<0)) != 0);                        int j = ((b_2&(1<<1)) != 0);                        score += (double)(boundaries[0][j][1]/boundaries[0][j][0])*(boundaries[1][j][1]/boundaries[1][j][0])*(double)per_branch[j]/total; //*(double)count[i][j]/per_branch[j];                        //cout << (double)(boundaries[0][j][1]/boundaries[0][j][0])*(boundaries[1][j][1]/boundaries[1][j][0])*(double)per_branch[j]/total <<endl;                    }                    //assert(0);                    //double score = (double)(per_branch[0]/total)*score_per_branch[0] + (double)(per_branch[1]/total)*score_per_branch[1];                    cout << dim_id <<" please work " << score <<endl;                    //cout << boundaries[0][1] <<" "<<boundaries[0][0] <<" " << boundaries[1][1] <<" "<<boundaries[1][0] <<endl;                    //cout << "new new metric: " << dim_id <<" :: "<< 1000*((double)(boundaries[0][1]-boundaries[0][0])+(double)(boundaries[1][1]-boundaries[1][0])) << endl;                }                cout << "dimension confusion" <<endl;                for(int i = 0;i<dimension_confusion.size();i++)                {                    dimension_confusion[i].vector_id = i;                    if(dimension_confusion[i].input_delta_sum != 0)                        dimension_confusion[i].score = dimension_confusion[i].ratio_sum/dimension_confusion[i].input_delta_sum;                    else                    {                        dimension_confusion[i].score = 0;                    }                    //dimension_error_ratio_score[i] =                    //dimension_confusion[i].score;                    cout << i <<" " <<dimension_confusion[i].score <<endl;                }                for(int category = 0;category<2;category++)                {                    //cout << "category "<<category <<endl;                    for(int i = 0;i<dimension_confusion_by_category[category].size();i++)                    {                        dimension_confusion_by_category[category][i].vector_id = i;                        if(dimension_confusion_by_category[category][i].input_delta_sum != 0)                            dimension_confusion_by_category[category][i].score = dimension_confusion_by_category[category][i].ratio_sum/dimension_confusion_by_category[category][i].input_delta_sum;                        else                        {                            dimension_confusion_by_category[category][i].score = 0;                        }                        //dimension_error_ratio_score[i] =                        //dimension_confusion[i].score;                        //cout << i <<" " <<dimension_confusion_by_category[category][i].score <<endl;                    }                }            }            for(int dimension_id = 0;dimension_id<latice->numInputs;dimension_id++)            {                if(dimension_input_delta_sum[dimension_id] != 0)                {                    dimension_error_ratio_score[dimension_id]                    = dimension_error_ratio_sum[dimension_id]/dimension_input_delta_sum[dimension_id];                }                else                {                    dimension_error_ratio_score[dimension_id] = 0;                }                int f_d_id = dimension_id;                if(double_dimension)                for(int s_d_id = f_d_id+1; s_d_id < latice->numInputs; s_d_id++)                {                    if(dimension_pair_input_delta_sum[f_d_id][s_d_id] != 0)                    {                        dimension_pair_error_ratio_score[f_d_id][s_d_id]                        = dimension_pair_error_ratio_sum[f_d_id][s_d_id]/dimension_pair_input_delta_sum[f_d_id][s_d_id];                    }                    else                    {                        dimension_pair_error_ratio_score[f_d_id][s_d_id] = 0;                    }                    for(int i = 0;i<2;i++)for(int j = 0;j<2;j++)                    {                        if(dimension_bit_pair_error_ratio_sum[i][j][f_d_id][s_d_id] != 0)                        {                            dimension_bit_pair_error_ratio_score[i][j][f_d_id][s_d_id]                            = dimension_bit_pair_error_ratio_sum[i][j][f_d_id][s_d_id]/dimension_bit_pair_input_delta_sum[i][j][f_d_id][s_d_id];//dimension_pair_input_delta_sum[f_d_id][s_d_id];                        }                        else                        {                            dimension_bit_pair_error_ratio_score[i][j][f_d_id][s_d_id] = 0;                        }                    }                }                if(inout_dimension)                for(int out_id = 0; out_id<latice->numOutputs; out_id++)                {                    inout_dimension_error_ratio_score[out_id][dimension_id] =                    inout_dimension_error_ratio_sum[out_id][dimension_id]/inout_dimension_input_delta_sum[out_id][dimension_id];                }            }            if(print_close_local_data_model)            {                vector<bit_signature> printt = sort_single_dimensions();                cout << "current metric:" << endl;                for(int i = 0;i<printt.size();i++)                {                    cout<< printt[i].vector_id <<" "<< printt[i].value <<endl;                }            }            return;            /*for(int i = 0;i<latice->numInputs;i++)             {             negative_dimensions[i]/=negative_delta_ins_sum[i];             positive_dimensions[i]/=positive_delta_ins_sum[i];             }             for(int i = 0;i<latice->size();i++)             {             for(int j = 0;j<latice->numInputs;j++)             {             care_dimension_per_example[i][j]/=care_delta_ins_sum[i][j];             dont_care_dimension_per_example[i][j]/=dont_care_delta_ins_sum[i][j];             }             }*/        }        int get_worst_dimension()        {            vector<int> dimensions;            for(int i = 0;i<dimension_error_ratio_score.size();i++)            {                dimensions.push_back(i);            }            return get_worst_dimension(dimensions);        }        int get_worst_dimension(vector<int> ids)        {            pair<double, int> ret = mp(0, -1);            bool no = true;            for(int at = 0, i = ids[at];at<ids.size();at++, i = ids[at])            {                double val = (double)dimension_error_ratio_score[i];                if(!isnan(val))                {                    if(val == 0)                    {                        no = false;                    }                    ret = max(ret, mp(val, i));                }                else                {                    no = false;                }            }            if(ret.f == 0)            {                assert(!no);                return -1;            }            else            {                return ret.s;//bit_signature((int)ret.s);            }        }        int get_best_dimension()        {            pair<double, int> ret = mp((1<<30), -1);            bool no = true;            for(int i = 0;i<dimension_error_ratio_score.size();i++)            {                double val = (double)dimension_error_ratio_score[i];                if(!isnan(val))                {                    if(val == 0)                    {                        no = false;                    }                    else                    {                        ret = min(ret, mp(val, i));                    }                }                else                {                    no = false;                }            }            if(ret.f == 0)            {                assert(!no);                assert(0);                return -1;            }            else            {                return ret.s;//bit_signature((int)ret.s);            }        }        void update_summary_error_mask(net* home, Data* latice, batch the_batch)        {            assert(prev_error_of_samples.size() == latice->size());            error_mask_per_dimension.resize(latice->numInputs, vector<bit_signature>(latice->numOutputs, 0));            the_batch.set_inputs(latice);            for(int i = 0;i<latice->size();i++)            {                batch_element updated_element = get_batch_element(home, latice, i);//sum_vector(get_error_vector(latice->out[i], forwardPropagate(latice->in[i], false)));                for(int dimension_id = 0;dimension_id<latice->numInputs;dimension_id++)                {                    error_mask_per_dimension[dimension_id] =                    pairwise_addition(                                      error_mask_per_dimension[dimension_id],                                      vector_value_product(                                                           abs(the_batch.input_average[dimension_id] - latice->in[i][dimension_id]),                                                           pairwise_negation(                                                                             prev_error_of_samples[i].error_vector,                                                                             updated_element.error_vector                                                                             )                                                           )                                      );                }            }            for(int i = 0;i<error_mask_per_dimension.size();i++)            {                error_mask_per_dimension[i] = vector_value_product(1.0/(double)latice->size(), error_mask_per_dimension[i]);            }            summary_error_mask.resize(latice->numOutputs, 0);            for(int out_id = 0;  out_id<summary_error_mask.size(); out_id++)            {                for(int in_id = 0;in_id<error_mask_per_dimension.size(); in_id++)                {                    summary_error_mask[out_id] += error_mask_per_dimension[in_id][out_id];                }                //noramlize?                //summary_error_mask[out_id]/=error_mask_per_dimension.size();            }        }        vector<bit_signature> sort_single_dimensions()        {            vector<bit_signature> ret;            for(int i = 0;i<dimension_error_ratio_score.size();i++)            {                dimension_error_ratio_score[i].vector_id = i;            }            ret = dimension_error_ratio_score;            sort_v(ret);            rev_v(ret);            return ret;        }        vector<vector<bit_signature> > sort_inout_dimensions()        {            vector<vector<bit_signature> > ret;            for(int i = 0;i<inout_dimension_error_ratio_score.size();i++)            {                for(int j = 0;j<inout_dimension_error_ratio_score[i].size();j++)                    inout_dimension_error_ratio_score[i][j].vector_id = j;                vector<bit_signature> local_ret = inout_dimension_error_ratio_score[i];                sort_v(local_ret);                rev_v(local_ret);                ret.push_back(local_ret);            }            return ret;        }        struct bit_dimension_pair        {            int f_bit;            int s_bit;            int f_dim;            int s_dim;            double val;            operator_signature the_gate;            bit_dimension_pair(int _f_bit,                               int _s_bit,                               int _f_dim,                               int _s_dim,                               double _val)            {                f_bit = _f_bit;                s_bit = _s_bit;                f_dim = _f_dim;                s_dim = _s_dim;                val = _val;            }            bit_dimension_pair(int _f_bit,                               int _s_bit,                               int _f_dim,                               int _s_dim,                               double _val,                               operator_signature _the_gate                               )            {                f_bit = _f_bit;                s_bit = _s_bit;                f_dim = _f_dim;                s_dim = _s_dim;                val = _val;                the_gate = _the_gate;            }            bool operator < (const bit_dimension_pair& other) const            {                return val<other.val;            }            string print()            {                string ret;                ret+="dim("+to_string(f_dim) + ", "+to_string(s_dim)+")at("+to_string(f_bit)+", "+to_string(s_bit)+") = "+to_string(val);                return ret;            }        };        vector<bit_dimension_pair> sort_functional_dimension_pairs(Data* latice)        {            vector<bit_dimension_pair> ret;            int numInputs = latice->numInputs;            for(int f_d = 0; f_d < numInputs; f_d++)            {                for(int s_d = f_d+1; s_d < numInputs; s_d++)                {                    for(int gate = 0; gate<16; gate++)                    {                        double sum[2] = {0, 0};                        for(int i = 0;i<2;i++)                        {                            for(int j = 0;j<2;j++)                            {                                int input = (i<<0)|(j<<1);                                int output = ((gate&(1<<input)) != 0);                                sum[output] += dimension_bit_pair_error_ratio_score[i][j][f_d][s_d];                            }                        }                        sum[0]/=dimension_pair_error_ratio_score[f_d][s_d];                        sum[1]/=dimension_pair_error_ratio_score[f_d][s_d];                        ret.push_back({-1, -1, f_d, s_d, sum[0]/sum[1], operator_signature(gate, f_d, s_d)});                    }                }            }            sort_v(ret);            return ret;        }        vector<bit_dimension_pair> sort_bit_dimension_pairs(Data* latice)        {            vector<bit_dimension_pair> ret;            int numInputs = latice->numInputs;            for(int f_d = 0; f_d < numInputs; f_d++)            {                for(int s_d = f_d+1; s_d < numInputs; s_d++)                {                    for(int i = 0;i<2;i++)                    {                        for(int j = 0;j<2;j++)                        {                            ret.push_back({i, j, f_d, s_d, dimension_bit_pair_error_ratio_score[i][j][f_d][s_d]});                        }                    }                }            }            sort_v(ret);            rev_v(ret);            return ret;        }        vector<bit_dimension_pair> sort_dimension_pairs(Data* latice)        {            vector<bit_dimension_pair> ret;            int numInputs = latice->numInputs;            for(int f_d = 0; f_d < numInputs; f_d++)            {                for(int s_d = f_d+1; s_d < numInputs; s_d++)                {                    ret.push_back({-1, -1, f_d, s_d, dimension_pair_error_ratio_score[f_d][s_d]});                }            }            sort_v(ret);            rev_v(ret);            return ret;        }        void print(Data *latice)        {            int numInputs = latice->numInputs;            for(int f_d = 0; f_d < numInputs; f_d++)            {                for(int s_d = f_d+1; s_d < numInputs; s_d++)                {                    cout <<"("<<f_d <<", "<< s_d <<")"<<endl;                    cout << dimension_pair_error_ratio_score[f_d][s_d] <<" :: " <<endl;                    for(int i = 0;i<2;i++)                    {                        for(int j = 0;j<2;j++)                        {                            cout <<(double) dimension_bit_pair_error_ratio_score[i][j][f_d][s_d] <<" "<<i <<" "<< j <<endl;                        }                    }                    cout << endl;                    cout << endl;                }            }            vector<bit_dimension_pair> sorted_bit_dimension_pairs = sort_bit_dimension_pairs(latice);            for(int i = 0;i<sorted_bit_dimension_pairs.size();i++)            {                cout << sorted_bit_dimension_pairs[i].print() <<endl;            }            vector<bit_dimension_pair> sorted_dimension_pairs = sort_dimension_pairs(latice);            for(int i = 0;i<sorted_dimension_pairs.size();i++)            {                cout << sorted_dimension_pairs[i].print() <<endl;            }            //assert(0);        }    };    data_model the_model;    double get_error_of_maximal_error_example(Data* latice, parameters param)    {        batch ret = get_maximal_error_example(latice, param.get_rate(), 1);        return ret.elements[0].error;    }    batch stocastic_priority(Data* latice, parameters param)    {        batch ret;        ret.push_back(get_batch_element(this, latice, rand(0, latice->size()-1)));        return ret;    }    batch average_priority(Data* latice, parameters param)    {        //return get_batch_of_maximal_error_examples(latice, param);        batch ret;        for(int i = 0;i<latice->size();i++)        {            ret.push_back(get_batch_element(this, latice, i));        }        return ret;    }    void train_to_neutral_data(Data* latice, parameters param)    {        if(param.neural_net!=NULL)        {            layers = param.neural_net->layers;            return;        }        Data neutral;        latice->make_neutral(neutral);        double max_error;        do        {            batch the_batch = get_batch_of_maximal_error_examples(latice, param);            max_error = get_error_of_maximal_error_example(latice, param);            int num_ids = (int)the_batch.elements.size();            for(int i = 0;i<num_ids;i++)            {                int id = the_batch.elements[i].id;                vector<bit_signature> errors = forwardPropagate(latice->in[id], true);                backwardPropagate(latice->out[id], errors, param.get_rate(), false);            }            batchApplyDeltaWeights();            cout << max_error << endl;        } while(max_error>0.001);    }    class test_score    {    public:        vector<vector<bit_signature> > error_vectors_per_example;        vector<vector<bool> > correct_out_dimensions;        int num_output_dimensions_wrong = 0;        vector<bit_signature> error_per_example;        vector<bool> correct_examples;        int num_examples_wrong = 0;        int get_correct()        {            return (int)correct_examples.size()-num_examples_wrong;        }        int get_wrong()        {            return num_examples_wrong;        }        bool is_solved()        {            return get_wrong() == 0;        }        void check_accuracy_per_out_dimension(double accuracy_per_out_dim)        {            for(int i = 0;i<error_vectors_per_example.size();i++)            {                vector<bool> track_correct;                bool is_wrong = 0;                for(int j = 0;j<error_vectors_per_example[i].size();j++)                {                    if((double)error_vectors_per_example[i][j] > accuracy_per_out_dim)                    {                        num_output_dimensions_wrong++;                        track_correct.push_back(0);                        is_wrong = 1;                    }                    else                    {                        track_correct.push_back(1);                    }                }                correct_examples.push_back(!is_wrong);                num_examples_wrong+=is_wrong;                correct_out_dimensions.push_back(track_correct);            }        }        /*        void check_accuracy_per_example(double accuracy_per_example)        {            for(int i = 0;i<error_per_example.size();i++)            {                if((double)error_per_example[i] > accuracy_per_example)                {                    num_examples_wrong++;                    correct_examples.push_back(0);                }                else                {                    correct_examples.push_back(1);                }            }        }*/    };    test_score test(Data* latice, double dual_accuracy)    {        test_score ret;        for(int i = 0;i<latice->size();i++)        {            vector<bit_signature> predict = forwardPropagate(latice->in[i], false);            ret.error_vectors_per_example.push_back(get_error_vector(latice->out[i], predict, 1));            ret.error_per_example.push_back(sum_vector(get_error_vector(latice->out[i], predict, 1)));        }        ret.check_accuracy_per_out_dimension(dual_accuracy);        //ret.check_accuracy_per_example(dual_accuracy);        return ret;    }    double get_error_of_data(Data* latice)    {        double ret = 0;        for (int i = 0; i < latice->size(); ++i)        {            vector<bit_signature> predict = forwardPropagate(latice->in[i], false);            //ret += sum_vector(get_error_vector(latice->out[i], predict, 1));            ret=max(ret, sum_vector(get_error_vector(latice->out[i], predict, 1)));        }        return ret;    }    int PriorityTrain(Data *latice, parameters param, batch (net::*priority_function)(Data*, parameters))    {        int trainSetSize = latice->sampleSize;        int itteration_no = 0;        //train_to_neutral_data(latice, param);        the_model = data_model(this, latice);        double prev_min_max_error = get_error_of_maximal_error_example(latice, param);        vector<bit_signature> min_max_error(1, prev_min_max_error);        int total_iter = 0;        for(int i = 0; i<param.get_number_resets();i++)        {            if(i!=0)            {                assert(0);                set_random_w();                itteration_no = 0;            }            while(!training_completed(latice, param.accuracy) && param.do_next_iteration(itteration_no))            {                total_iter ++;                //double local_rate = (max_rate - min_rate)*((double)count_unknown_examples(latice)/latice->size())+min_rate;                double local_rate = param.get_rate();                batch the_batch = (this->*priority_function)(latice, param);                //batch the_batch = the_model.calculate_confusion(latice, param, this);                /*for(int i = 0;i<the_batch.elements.size();i++)                {                    cout << latice->printInput(the_batch.elements[i].id) <<" ";                }                cout << endl;*/                double new_max_error = get_error_of_maximal_error_example(latice, param);                prev_min_max_error = min(prev_min_max_error, new_max_error);                min_max_error.push_back(min((double)min_max_error[min_max_error.size()-1], new_max_error));                if(param.num_stale_iterations_defined)                {                    if(min_max_error.size() >= param.num_stale_iterations && min_max_error[min_max_error.size()-1] == min_max_error[(min_max_error.size()-1)-param.num_stale_iterations])                    {                        break;                    }                    else                    {                        //cout << fixed << setprecision(12) << update_model <<" :: "<<prev_min_max_error <<" "<< new_max_error << endl;                    }                }                int num_ids = (int)the_batch.elements.size();                {                    vector<bit_signature> sum_prev_errors(latice->numOutputs, 0);                    vector<bit_signature> sum_after_errors(latice->numOutputs, 0);                    for(int i = 0;i<num_ids;i++)                    {                        int id = the_batch.elements[i].id;                        vector<bit_signature> errors = forwardPropagate(latice->in[id], true);                        sum_prev_errors = pairwise_addition(errors, sum_prev_errors);                        backwardPropagate(latice->out[id], errors, local_rate, false);                    }                    batchApplyDeltaWeights();                    for(int i = 0;i<num_ids;i++)                    {                        int id = the_batch.elements[i].id;                        vector<bit_signature> errors = forwardPropagate(latice->in[id], false);                        sum_after_errors = pairwise_addition(errors, sum_prev_errors);                    }                    double error_ration = sum_vector(sum_after_errors)/sum_vector(sum_prev_errors);                    vector<bit_signature> error_ratio_vector = pairwise_division(sum_after_errors, sum_prev_errors);                    if(param.track_dimension_model)                    {                        //assert(0);                        the_model.update_dimension_summary(this, latice, the_batch, error_ratio_vector, error_ration);                        //if(!param.do_next_iteration(itteration_no+1))                        if(print_close_local_data_model)the_model.calculate_confusion(latice, param, this);                    }                    //update_summary_error_mask(latice, batch, prev_error_of_samples);                }                if(printOnlyBatch)                {                    for(int i = 0;i<num_ids;i++)                    {                        cout << the_batch.elements[i].id <<" ";                    }                    //cout << endl;                }                if(printCleanItteration)                {                    cout << itteration_no << "\t" << get_maximal_error_example(latice, local_rate, 1).error_average <<endl;                }                if(printItteration)                {                    test_score local_result = test(latice, param.accuracy);                    for(int i=0;i<local_result.correct_examples.size();i++)                    {                        cout << local_result.correct_examples[i];                    }                    cout << " iter = " << itteration_no <<" ";                    cout << " ids: ";                    for(int i = 0;i<num_ids;i++)                    {                        cout << the_batch.elements[i].id <<" ";                    }                    cout << fixed << setprecision(3) << " error = " << get_maximal_error_example(latice, local_rate, 1).error_average << " #true " << local_result.get_correct() << " #false = " << local_result.get_wrong() << " rate = " << local_rate << endl;                    //printWeights();                }                itteration_no++;                if(itteration_no %1000 == 0)                {                    cout << "itteration num = " <<itteration_no <<endl;                }            }        }        if(printOnlyBatch)cout << endl;        //cout << "end" <<endl;        if(total_iter >= 1)the_model.close(latice);        if(print_discrete_model)the_model.print(latice);        return total_iter;    }    int queueTrain(Data *latice, double rate)    {        queue<int> q_init;        queue<int> q_error;        queue<int> q_correct;        clearQueue(&q_init);        clearQueue(&q_error);        clearQueue(&q_correct);        int Learning = 0;        bool Learned = false;        int totalErrors = 0;        int totalCorrect = 0;        int passedErrors = 0;        int passedCorrect = 0;        int setStress = 1;        int cycleErrors = 0;        int currentErrors = (1<<30);        int lastCycleErrors = (1<<30);        int trainSetSize = latice->sampleSize;        int c = 0;        int cycle = 0;        for(int i=0; i<trainSetSize; i++)        {            c++;            q_init.P(i);        }        int iteration_no = 0;        double accuracy = 0.5;        while(!Learned&&(!q_init.empty()||!q_error.empty()||!q_correct.empty()))        {            int id;            if(!q_init.empty())            {                id = q_init.front();                q_init.pop();            }            else if(!q_error.empty()&&((passedCorrect>passedErrors)||q_correct.empty()))            {                id = q_error.front();                q_error.pop();                passedErrors++;            }            else if(!q_correct.empty())            {                id = q_correct.front();                q_correct.pop();                passedCorrect++;            }            else            {                assert(0);            }            c--;            vector<bit_signature> predict = forwardPropagate(latice->in[id], 1);            bool correct = check(latice->out[id], predict, accuracy);            stress = setStress;            while(!correct && stress--)            {                assert(0);                //correct = update_and_test(latice, id, predict, rate);                Learning = false;                cycleErrors++;            }            if(!correct)            {                q_error.P(id);                totalErrors++;            }            else            {                q_correct.P(id);                totalCorrect++;            }            currentErrors = totalErrors - passedErrors;            if(printCleanItteration)            {                int next_id = get_maximal_error_example(latice, rate, 1).elements[0].id;                cout << iteration_no << "\t" << next_id <<endl;            }            if(printItteration)            {                assert(0);//accuracy                test_score local_result = test(latice, 0.5);                for(int i=0;i<local_result.correct_examples.size();i++)                {                    cout << local_result.correct_examples[i];                }                cout << " ids: " << id;                cout << " #true " << local_result.get_correct() << endl;                //printWeights();            }            currentErrors = totalErrors - passedErrors;            if(c==0)            {                cycle++;                c = trainSetSize;                double delta = lastCycleErrors-cycleErrors;                if(printCycle)                {                    cout << cycle <<  ": currentErrors = "<< currentErrors << " CycleErrors = " << cycleErrors << " delta = " << delta << "  rate = " << rate << endl;                    print_max_feature_of_dimension(dimension_difficulty_score, "dimension difficulty");                    //print_max_feature_of_dimension(dimension_easy_score, "dimension easy");                }                lastCycleErrors = cycleErrors;                cycleErrors = 0;                //rate *=0.99;//((double)(currentErrors+cycleErrors)/c);                //analyzeMistakes(latice);            }            Learning += (currentErrors == 0);            Learned = (Learning > trainSetSize);            iteration_no++;        }        if(printCycle)        {            cout <<"numCycles: "<< cycle <<endl;        }        return iteration_no;    }    int fullBatchTrain(Data *latice, double rate)    {        bool solved = false;        int iteration_no = 0;        double accuracy = 0.5;        assert(0);        while(!solved)        {            for(int i = 0;i<latice->size();i++)            {                vector<bit_signature> predictedOutput = forwardPropagate(latice->in[i], true);                backwardPropagate(latice->out[i], predictedOutput, rate, false);            }            batchApplyDeltaWeights();            if(printCleanItteration)            {                cout << iteration_no <<"\t"<< get_maximal_error_example(latice, rate, 1).error_average <<endl;            }            solved = true;            for(int i = 0;i<latice->size();i++)            {                vector<bit_signature> predict = forwardPropagate(latice->in[i], 0);                bool correct = check(latice->out[i], predict, accuracy);                solved = solved&correct;                if(printItteration)cout << correct;            }            if(printItteration)cout <<" "<< iteration_no << endl;            iteration_no++;        }        return iteration_no;    }    /*pair<vector<pair<int, vector<bit_signature> > >, int>  test(Data *testData)    {        vector<pair<int, vector<bit_signature> > > ret;        int num_wrong = 0;        int num_correct = 0;        for(int i=0; i<testData->in.size(); i++)        {            vector<bit_signature> predict = forwardPropagate(testData->in[i], 0);            vector<bit_signature> delta_predict_out = delta(testData->out[i], predict);            int num_bits_wrong = 0;            for(int j=0;j<delta_predict_out.size();j++)            {                num_bits_wrong+=abs(delta_predict_out[j]);            }            if(num_bits_wrong!=0)            {                num_wrong++;            }            else            {                assert(num_bits_wrong>=0);                num_correct++;            }            ret.pb(mp(num_bits_wrong, predict));        }        return mp(ret, num_wrong);    }*/    /*bool test(Data *testData, string action, double accuracy)    {        if(action == "print result")        {            pair<vector<pair<int, vector<bit_signature> > >, int> result = test(testData);            return reportTest(testData, result.s);        }        else if(action == "no action")        {            return training_completed(testData, accuracy);        }        else        {            assert(0);            cout << "WTF" <<endl;            return false;        }    }*/    /*bool reportTest(Data *testData, int wrong)    {        cout << "correct: " <<  testData->sampleSize-wrong <<" out of " << testData->sampleSize << endl;        if(wrong!=0)        {            cout << wrong <<" wrong " << endl;        }        return wrong == 0;    }*/    void clearQueue(queue<int> *q)    {        while(!q->empty())        {            q->pop();        }    }    void announceTrain(Data *latice)    {        cout << "Start train on: bits: " << numInputs <<" samples: "<< latice->sampleSize <<endl;    }    void analyzeEvolve()    {        cout << "Analyze Evolve: " << endl;        vector<bit_signature> prev = evolve[0].f[evolve[0].f.size()-1].neurons[0].w;        for(int i=1;i<evolve.size();i++)        {            vector<bit_signature> w = evolve[i].f[evolve[i].f.size()-1].neurons[0].w;            cout << evolve[i].s <<" :: ";            for(int w_id = 0;w_id<w.size();w_id++)            {                string buf = "";                if(w[w_id] >= 0) buf = " ";                cout << fixed << setprecision(6) << buf << w[w_id] << " ";                prev[w_id] = w[w_id];            }            cout << endl;        }    }    void dfs(int at, int c)    {        color[at] = c;        sorted_samples.pb(at);        for(int i=0;i<MST[at].size();i++)        {            int next = MST[at][i].f;            if(color[next]==0)            {                dfs(next, c);            }            else            {            }        }    }    vector<int> color;    vector<int> sorted_samples;    vector<vector<pair<int, int> > > MST;    vector<vector<pair<int, int> > > fullOrder;    vector<int> father;    int Find(int x)    {        if(x==father[x])            return x;        return father[x] = Find(father[x]);    }    void unite(int x, int y)    {        father[Find(x)] = Find(y);    }    void MST_of_samples(Data *latice)    {        /*         todo: create categories         */        sort_v(state_action_reward);        //rev_v(state_action_reward);        MST.clear();        father.clear();        fullOrder.clear();        for(int i=0;i<latice->sampleSize;i++)        {            vector<pair<int, int> > v;            MST.pb(v);            father.pb(i);            fullOrder.pb(v);        }        int taken_edge = 0;        for(int i=0;i<state_action_reward.size();i++)        {            int reward = state_action_reward[i].f;            int x = state_action_reward[i].s.f, y = state_action_reward[i].s.s;            if(reward>0)            {                fullOrder[x].pb(mp(y, reward));                fullOrder[y].pb(mp(x, reward));            }            if(printStateActionReward)            {                cout << bitset<10>(x).to_string() <<" "<< bitset<10>(y).to_string() <<" " << reward << endl;            }            if(Find(x)!=Find(y))            {                unite(x, y);                MST[x].pb(mp(y, reward));                MST[y].pb(mp(x, reward));                taken_edge++;            }            else            {            }        }        if(printFullOrder)        {            cout << "Full order " << fullOrder.size() <<endl;            for(int i=0;i<fullOrder.size();i++)            {                cout <<latice->printInput(i) << ": ";                for(int j=0;j<fullOrder[i].size();j++)                {                    cout << latice->printInput(fullOrder[i][j].f) << " " << fullOrder[i][j].s <<" | ";                }                cout << endl;            }        }        if(printMST)        {            cout << "MST " << MST.size() << endl;            for(int i=0;i<MST.size();i++)            {                latice->printInput(i); cout << ": ";                for(int j=0;j<MST[i].size();j++)                {                    latice->printInput(MST[i][j].f); cout << " " << MST[i][j].s <<" | ";                }                cout << endl;            }        }    }    vector<pair<int, pair<int, int> > > state_action_reward;    vector<pair<int, pair<int, int> > > similar;    vector<pair<int, pair<int, int> > > different;    string printVector(vector<bit_signature> v)    {        string ret = "";        for(int i=0;i<v.size();i++)        {            if(v[i]==1)            {                ret+='+';            }            else if(v[i]==0)            {                ret+='_';            }            else if(v[i]==-1)            {                ret +='-';            }            else            {                assert(0);            }        }        return ret;    }    void printDeltaState(deltaState at, Data* latice)    {        deltaPredict deltaActor = at.f.f, deltaHint = at.f.s;        cout << "learned: " << latice->printInput(deltaActor.f) <<" at "<< printVector(deltaActor.s);        cout <<" | unlearned: " << latice->printInput(deltaHint.f) <<" at "<< printVector(deltaHint.s) <<" | mask: "<< printVector(at.s);    }    void printNewNeuron(pair<pair<int, vector<bit_signature> >, vector<bit_signature> > at, Data* latice)    {        cout << "Change in predict :: hint: " << latice->printInput(at.f.f) <<" at "<< printVector(at.f.s) <<" | mask: "<< printVector(at.s);    }    vector<pair<int, vector<bit_signature> > > important_neurons;    int get_important_neurons()    {        important_neurons.clear();        for(map<vector<bit_signature>, int>::iterator it = count_neuron_activation.begin();it!=count_neuron_activation.end();it++)        {            important_neurons.pb(mp((*it).s, (*it).f));        }        sort_v(important_neurons);        rev_v(important_neurons);        if(important_neurons.size()>=1)        {            vector<bit_signature> get_important_dimensions = vector<bit_signature>(important_neurons[0].s.size(), 0);            for(int i = 0;i<important_neurons.size();i++)            {                for(int j = 0; j<important_neurons[i].s.size();j++)                {                    get_important_dimensions[j]+= //log2(important_neurons[i].f)*(important_neurons[i].s[j]!=0);                    important_neurons[i].f*important_neurons[i].f*(important_neurons[i].s[j]!=0);                }            }            //cout << "important dimensions" << endl;            pair<double, int> ret = mp(-1, -1);            for(int i = 0;i<get_important_dimensions.size();i++)            {                ret = max(ret, mp((double)get_important_dimensions[i], i));                //cout << get_important_dimensions[i]<<" ";            }            //cout << endl;            return ret.s;        }        return -1;    }    void analyzeMistakes(Data *latice)    {        if(print_implications)        {            vector<pair<int, pair<int, int> > > sorted_implications;            for(map<pair<int,int>, int>::iterator it = learned_implication.begin(); it!=learned_implication.end(); it++)            {                sorted_implications.push_back(make_pair((*it).s, (*it).f));            }            sort_v(sorted_implications);            rev_v(sorted_implications);            for(int i = 0;i<sorted_implications.size();i++)            {                cout << printVector(latice->in[sorted_implications[i].s.f]) <<" => "<< printVector(latice->in[sorted_implications[i].s.s]) <<" :: " << sorted_implications[i].f <<endl;                if(sorted_implications[i].first == 1)                {                    break;                }            }            cout << endl;        }        vector<pair<int, deltaState> > sorted_nodes;        vector<pair<int, pair<pair<int, vector<bit_signature> >, vector<bit_signature> > > > sorted_neurons;        if(print_delta_knowledge_graph)        {            for(map<deltaState, int>::iterator it = delta_knowledge_graph.begin(); it != delta_knowledge_graph.end(); it++)            {                deltaState at = (*it).f;                int rez = (*it).s;                sorted_nodes.pb(mp(rez, at));            }            sort_v(sorted_nodes);            rev_v(sorted_nodes);            cout << "delta_knowledge_graph : " << delta_knowledge_graph.size() <<endl;            for(int i=0;i<sorted_nodes.size();i++)            {                printDeltaState(sorted_nodes[i].s, latice);                cout << " = " << sorted_nodes[i].f <<endl;                if(sorted_nodes[i].f == 1)                {                    cout << ". . . " << sorted_nodes.size()-i << " more" <<endl;                    break;                }            }        }        /*         for(map<pair<pair<int, vector<bit_signature> >, vector<bit_signature> >, int>::iterator it = new_neurons.begin(); it != new_neurons.end(); it++)         {         pair<pair<int, vector<bit_signature> >, vector<bit_signature> > at = (*it).f;         int rez = (*it).s;         sorted_neurons.pb(mp(rez, at));         }         cout << endl;         cout << "new neurons: " << new_neurons.size() << endl;         sort_v(sorted_neurons);         rev_v(sorted_neurons);         for(int i=0;i<sorted_neurons.size();i++)         {         printNewNeuron(sorted_neurons[i].s, latice);         cout << " = " << sorted_neurons[i].f <<endl;         }         cout << endl;*/        if(print_classify_neurons)        {            cout << "classify neurons ( categories ) : "<< clasify_neurons.size() <<endl;            for(map<vector<bit_signature>, set<deltaState> >::iterator it = clasify_neurons.begin();it!=clasify_neurons.end();it++)            {                vector<bit_signature> new_neuron = (*it).f;                set<deltaState> knowledge = (*it).s;                cout << printVector(new_neuron) <<" :: "<<endl;;                for(set<deltaState>::iterator i=knowledge.begin();i!=knowledge.end();i++)                {                    cout << " ";                    printDeltaState((*i), latice);                    cout << " = "<< delta_knowledge_graph[(*i)] <<endl;                }            }        }        if(print_important_neurons)        {            get_important_neurons();            cout << endl;            cout << "important neurons: " << important_neurons.size() << endl;            for(int i = 0;i<important_neurons.size();i++)            {                cout << printVector(important_neurons[i].s) <<" :: "<< important_neurons[i].f <<endl;                if(important_neurons[i].f <= 3)                {                    cout << ". . . " << important_neurons.size() - i << " more" <<endl;                    break;                }            }        }        state_action_reward.clear();        for(int i=0;i<latice->sampleSize;i++)        {            for(int j=i+1;j<latice->sampleSize;j++)            {                int type_ij_11 = state_action_change[mp(mp(i, 1), mp(1, j))];                int type_ji_11 = state_action_change[mp(mp(j, 1), mp(1, i))];                int type_ij_01 = state_action_change[mp(mp(i, 0), mp(1, j))];                int type_ij_10 = state_action_change[mp(mp(i, 1), mp(0, j))];                int type_ji_01 = state_action_change[mp(mp(j, 0), mp(1, i))];                int type_ji_10 = state_action_change[mp(mp(j, 1), mp(0, i))];                int type_ji_00 = state_action_change[mp(mp(j, 0), mp(0, i))];                int type_ij_00 = state_action_change[mp(mp(i, 0), mp(0, j))];                //    TODO: implement dynamic tree builing based on training's current state. initiated xD                int reward = type_ij_01  + type_ji_01;                reward*=(type_ji_10 + type_ij_10 == 0);                reward -= type_ji_10 + type_ij_10 ;                state_action_reward.pb(mp(reward, mp(i, j)));            }        }    }    vector<int> topologicalSortOfSamples(Data *latice)    {        analyzeMistakes(latice);        assert(state_action_reward.size()>=1);//latice->sampleSize);        MST_of_samples(latice);        sorted_samples.clear();        color.assign(latice->sampleSize, 0);        dfs(state_action_reward[0].s.f, 1);        if(printTopologicalOrder)        {            cout << "Topological Order: "<< sorted_samples.size() <<endl;            for(int i=0;i<sorted_samples.size();i++)            {                cout << bitset<10>(sorted_samples[i]).to_string() <<" ";            }            cout << endl;        }        return sorted_samples;    }};net::parameters standard_param(double treshold){    net::parameters param = net::parameters(1, 1);    param.accuracy = treshold;    param.track_dimension_model = false;    param.priority_train_f = &net::softPriorityTrain;    return param;}net::parameters cutoff_param(int cutoff_iter, double treshold){    net::parameters param = standard_param(treshold);    param.set_iteration_count(cutoff_iter);    return param;}net::parameters meta_cutoff(int root_iter, int leaf_iter){    net::parameters param = standard_param(0.01);    param.set_meta_iteration_count(root_iter);    param.set_iteration_count(leaf_iter);    return param;}#endif //NEURAL_GUIDED_DECISION_TREE_SYNTHESIS_NET_H